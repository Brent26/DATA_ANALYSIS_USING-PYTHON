{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# A) library importation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import openpyxl as px\n",
        "import warnings\n",
        "from IPython.display import display \n",
        "from scipy.stats import skew\n",
        "from scipy.stats import chi2_contingency\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'seaborn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {},
      "id": "d82ae761"
    },
    {
      "cell_type": "code",
      "source": [
        "# B) Loading data set \n",
        "filepath = \"churn_real.xlsx\"\n",
        "df = pd.read_excel(filepath, engine='openpyxl')\n",
        "# Engine is needed for .xlsx files\n",
        "\n",
        "# Code to check contents\n",
        "missing_all = df.isnull().sum().sort_values(ascending=False)\n",
        "display(missing_all)\n",
        "print(\"First 10 rows:\")\n",
        "display(df.head(10))\n",
        "display(df.columns.tolist())\n",
        "display(df.describe(include='all'))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "e0b6c1fd"
    },
    {
      "cell_type": "code",
      "source": [
        "# C) Total Charges numeric conversion\n",
        "print(df['Total Charges'].dtype)\n",
        "\n",
        "df['Total Charges'] = pd.to_numeric(df['Total Charges'], errors='coerce')\n",
        "#coerce will convert non-numeric values to NaN\n",
        "print(df['Total Charges'].dtype)\n",
        "\n",
        "print(\"Missing values in Total Charges:\", df['Total Charges'].isnull().sum())\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "01a185ed"
    },
    {
      "cell_type": "code",
      "source": [
        "# D) Summary statistics visualization\n",
        "desc = df.describe().drop(\"count\")\n",
        "#\n",
        "styled_desc = desc.style\\\n",
        "    .set_properties(**{\n",
        "        'background-color': 'lightgrey',\n",
        "        'text-align': 'center',\n",
        "        'color': 'black'\n",
        "    })\\\n",
        "    .set_table_styles([\n",
        "        {\n",
        "            'selector': 'thead th',\n",
        "            'props': [\n",
        "                ('background-color', 'navy'),\n",
        "                ('color', 'black'),\n",
        "                ('text-align', 'center')\n",
        "            ]\n",
        "        }\n",
        "    ])\n",
        "\n",
        "# Display the styled DataFrame\n",
        "display(styled_desc)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "9e7ca6f0"
    },
    {
      "cell_type": "code",
      "source": [
        "# E)Customer Churn Anaylsis\n",
        "relevant_numeric_data = ['Monthly Charges', 'Total Charges', 'Tenure Months','CLTV']\n",
        "# creates a list of columns of interest\n",
        "\n",
        "print(\"Data types of relevant numeric columns:\")\n",
        "print(df[relevant_numeric_data].dtypes)\n",
        "\n",
        "means = df.groupby('Churn Label')[relevant_numeric_data].mean()\n",
        "# calculates the mean of the relevant numeric columns grouped by Churn Label                            \n",
        "\n",
        "print(df[relevant_numeric_data].dtypes)\n",
        "\n",
        "n_cols = 2\n",
        "n_rows = (len(relevant_numeric_data) + 1) // n_cols\n",
        "# calculates the number of rows needed for the subplots\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, n_rows * 4))\n",
        "axes = axes.flatten()\n",
        "# flattens the axes array to make it easier to iterate over\n",
        "\n",
        "for i, col in enumerate(relevant_numeric_data):\n",
        "    ax = axes[i]\n",
        "    sns.barplot(x=means.index, y=means[col], ax=ax, palette=\"Set2\")\n",
        "    \n",
        "    ax.set_title(f'Average {col} by Churn Label', fontsize=12)\n",
        "    ax.set_xlabel(\"Churn Label\")\n",
        "    ax.set_ylabel(f'Mean {col}')\n",
        "    \n",
        "    for p in ax.patches:\n",
        "        value = p.get_height()\n",
        "        ax.annotate(f'{value:.1f}', (p.get_x() + p.get_width()/2, value + 0.5),\n",
        "                    ha='center', fontsize=10)\n",
        "        \n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "    # delete unused subplots\n",
        "\n",
        "plt.tight_layout()\n",
        "# Adjust layout to prevent overlap\n",
        "plt.show()\n",
        "    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "27b8a50a"
    },
    {
      "cell_type": "code",
      "source": [
        "# G) Churn Distribution Visualization\n",
        "churn_counts = df['Churn Label'].value_counts()\n",
        "\n",
        "# Pie chart settings\n",
        "colors = ['#1f3b73', '#ff7f0e']\n",
        "explode = (0.05, 0.05)  # slightly pull apart the slices\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(churn_counts, labels=churn_counts.index, autopct='%1.1f%%',\n",
        "        startangle=90, colors=colors, explode=explode, shadow=True)\n",
        "plt.title(\"Customer Churn Distribution\")\n",
        "plt.axis('equal')  # Equal aspect ratio ensures the pie is circular.\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "a416faab"
    },
    {
      "cell_type": "code",
      "source": [
        "# H)Variable vs Churn Correlation Analysis\n",
        "exclude_cols = ['CustomerID', 'Lat long', 'Zip Code', 'Churn Reason', 'Churn Label', 'Country', 'State']\n",
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "categorical_cols = [col for col in categorical_cols if col not in exclude_cols]\n",
        "\n",
        "n_cols = 2\n",
        "n_rows = (len(categorical_cols) + 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 5))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(categorical_cols):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # Top 5 most common values in this column\n",
        "    top_5 = df[col].value_counts().nlargest(5).index\n",
        "    df_top = df[df[col].isin(top_5)].copy()\n",
        "    \n",
        "    # ✅ Use df_top for cleaner charts\n",
        "    sns.countplot(data=df_top, x=col, hue='Churn Label', ax=ax)\n",
        "    ax.set_title(f'{col} vs Churn', fontsize=12)\n",
        "    ax.set_xlabel(col)\n",
        "    ax.set_ylabel(\"Count\")\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "        ax.annotate(f'{int(height)}',\n",
        "                    (p.get_x() + p.get_width() / 2., height + 1),\n",
        "                    ha='center', fontsize=9)\n",
        "\n",
        "    ax.legend(title=\"Churn\")\n",
        "\n",
        "# Clean up unused plots\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "66688fc5"
    },
    {
      "cell_type": "code",
      "source": [
        "# I) Churn Reason Analysis\n",
        "# Step 1: Count churn reasons\n",
        "reason_counts = df['Churn Reason'].value_counts()\n",
        "\n",
        "# Step 2: Calculate percentages\n",
        "reason_percent = df['Churn Reason'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Step 3: Combine into one DataFrame\n",
        "churn_summary = pd.DataFrame({\n",
        "    'Count': reason_counts,\n",
        "    'Percentage': reason_percent\n",
        "})\n",
        "\n",
        "# Step 4: Format percentages to 1 decimal place with %\n",
        "churn_summary['Percentage'] = churn_summary['Percentage'].map(\"{:.1f}%\".format)\n",
        "\n",
        "churn_summary.index.name = 'Churn Reason'\n",
        "churn_summary.reset_index(inplace=True)\n",
        "\n",
        "# Display result\n",
        "display(churn_summary)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "8889c876"
    },
    {
      "cell_type": "code",
      "source": [
        "#j) Churn Reason Evaluation\n",
        "# As seen by the screenshot provided above the top 3 churn reasons are as follows:\n",
        "# - Attitude of support Person\n",
        "# - Competitors offering higher download speed\n",
        "# - Competitors offering more data\n",
        "\n",
        "# Suggested mitigation strategies or changes would be:\n",
        "# -To train support personnel on human management skills as well as communication skills as soon as possible \n",
        "# since the churn percentage is the highest at 10.3% which is quite significant for an issue that can be resolved \n",
        "# relatively quickly, or implement an automatic response system that has been trained to deal with customers \n",
        "# effectively and fast.\n",
        "# -As for dealing with competitors offering higher download speed, it would be advisable to outperform competitors \n",
        "# in this aspect or match them, if not improve or strengthen other aspects such as reliability and/or signal \n",
        "# connectivity to keep customers happy. Some may prefer quality/functionality over quantity.\n",
        "# -Lastly, competitors offering more data, this can be mitigated by offering customers equal levels of data but \n",
        "# at a much lower price or monthly discounts on data packages. \n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "26e96443"
    },
    {
      "cell_type": "code",
      "source": [
        "##PART_B"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "a8a34fe4"
    },
    {
      "cell_type": "code",
      "source": [
        "# A)Missing values Identification\n",
        "\n",
        "# Display all variables and their missing values\n",
        "missing_values = df.isnull().sum()\n",
        "missing_values = missing_values[missing_values > 0]  # Filter only variables with missing values\n",
        "print(\"Variables with missing values:\")\n",
        "display(missing_values)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "c530bd7c"
    },
    {
      "cell_type": "code",
      "source": [
        "# B) Replacing missing values with mode\n",
        "TOTAL_CHARGES_MODE= df['Total Charges'].mode()[0]\n",
        "print(\"Total Charges Mode:\", TOTAL_CHARGES_MODE)\n",
        "df['Total Charges'].fillna(TOTAL_CHARGES_MODE, inplace=True)\n",
        "print(\"Missing values in Total Charges:\", df['Total Charges'].isnull().sum())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "65420c0c"
    },
    {
      "cell_type": "code",
      "source": [
        "# C) Skewness Calculation and Plotting\n",
        "\n",
        "# Columns to exclude\n",
        "exclude = ['Latitude', 'Longitude', 'Churn Value', 'Churn Score','Zip Code', 'CustomerID', 'Count']\n",
        "\n",
        "# Get numeric columns excluding the above\n",
        "numeric_cols = df.select_dtypes(include='number').columns\n",
        "numeric_filtered = [col for col in numeric_cols if col not in exclude]\n",
        "\n",
        "# Calculate skewness\n",
        "skewness = df[numeric_filtered].skew().sort_values(ascending=False)\n",
        "skew_df = pd.DataFrame(skewness, columns=['Skewness'])\n",
        "\n",
        "display(skew_df)\n",
        "\n",
        "# Plot regression for each variable against 'Churn Score'\n",
        "for col in numeric_filtered: # fetches the columns that are not in the exclude list\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.regplot(x=col, y='Churn Score', data=df, scatter_kws={'alpha': 0.5}, line_kws={'color': 'red'})\n",
        "    plt.title(f'Regression Plot: {col} vs Churn Score')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Churn Score')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "for col in numeric_filtered: # fetches the columns that are not in the exclude list\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    for label in df['Churn Label'].unique():\n",
        "        sns.kdeplot(df[df['Churn Label'] == label][col], label=label, shade=True)\n",
        "    plt.title(f'KDE Plot of {col} by Churn Label')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "for col in numeric_filtered: # fetches the columns that are not in the exclude list\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.boxplot(x='Churn Label', y=col, data=df)\n",
        "    plt.title(f'Box Plot of {col} by Churn Label')\n",
        "    plt.xlabel('Churn Label')\n",
        "    plt.ylabel(col)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "cd5c26a2"
    },
    {
      "cell_type": "code",
      "source": [
        "#PART C\n",
        "# HYPOTHESIS TESTING\n",
        "# 1. Phone Service vs Churn Label\n",
        "# The null hypothesis is that there is no relationship between the phone service and churn label.\n",
        "# The alternative hypothesis is that there is a relationship between the phone service and churn label.\n",
        "\n",
        "\n",
        "contingency_table = pd.crosstab(df['Phone Service'], df['Churn Label'])\n",
        "\n",
        "# Perform chi-square test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"Contingency Table:\")\n",
        "display(contingency_table)\n",
        "\n",
        "print(f\"\\nChi-square Statistic: {chi2:.4f}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(f\"P-value: {p:.4f}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "03839825"
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Contract vs Churn Label\n",
        "# The null hypothesis is that there is no relationship between the contract type and churn label.\n",
        "# The alternative hypothesis is that there is a relationship between the contract type and churn label.\n",
        "\n",
        "contract_table = pd.crosstab(df['Contract'], df['Churn Label'])\n",
        "\n",
        "# Chi-square test\n",
        "chi2_contract, p_contract, dof_contract, expected_contract = chi2_contingency(contract_table)\n",
        "\n",
        "# Display Results\n",
        "display(contract_table)\n",
        "print(f\"Chi-square Statistic: {chi2_contract:.4f}\")\n",
        "print(f\"Degrees of Freedom: {dof_contract}\")\n",
        "print(f\"P-value1: {p_contract:.2e}\")\n",
        "\n",
        "if p_contract < 0.05:\n",
        "    print(\"P-value < 0.05 → Reject the null hypothesis: There IS a relationship.\")\n",
        "else:\n",
        "    print(\"P-value > 0.05 → Fail to reject the null hypothesis: NO significant relationship.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "7c033773"
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Senior Citizen vs Churn Label\n",
        "# The null hypothesis is that there is no relationship between the senior citizen and churn label.\n",
        "# The alternative hypothesis is that there is a relationship between the senior citizen and churn label.\n",
        "\n",
        "# Contingency Table\n",
        "senior_table = pd.crosstab(df['Senior Citizen'], df['Churn Label'])\n",
        "\n",
        "# Chi-square test\n",
        "chi2_senior, p_senior, dof_senior, expected_senior = chi2_contingency(senior_table)\n",
        "\n",
        "# Display Results\n",
        "display(senior_table)\n",
        "print(f\"Chi-square Statistic: {chi2_senior:.4f}\")\n",
        "print(f\"Degrees of Freedom: {dof_senior}\")\n",
        "print(f\"P-value: {p_senior:.2e}\")\n",
        "\n",
        "if p_senior < 0.05:\n",
        "    print(\"P-value < 0.05 → Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"P-value > 0.05 → Fail to reject the null hypothesis.\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "aeefffb7"
    },
    {
      "cell_type": "code",
      "source": [
        "# PART D\n",
        "\n",
        "# Step 1: Select numeric features (excluding non-relevant ones)\n",
        "features = ['Monthly Charges', 'Total Charges', 'Tenure Months', 'CLTV']\n",
        "X = df[features]\n",
        "\n",
        "# Step 2: Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Step 3: Apply the scaler\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Turn back into a DataFrame\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=features)\n",
        "\n",
        "# Preview\n",
        "X_scaled_df.head()\n",
        "\n",
        "X_scaled_df.describe().round(3)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "31ad9d1a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and testing sets\n",
        "y = df['Churn Label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, random_state= 50, stratify=y)\n",
        "\n",
        "X_train.shape\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "1c7dddbe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shape of the training and testing sets\n",
        "X_test.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "cbf1a93e"
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shape of the training and testing sets\n",
        "y_train.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "5d8e6e89"
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shape of the training and testing sets\n",
        "y_test.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "93062be8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model\n",
        "model = LogisticRegression(solver='liblinear', random_state=50)\n",
        "model.fit(X_train, y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "b12bdeb3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the test set results\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Checking the accuracy of the model\n",
        "model.score(X_test, y_test)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "2f46bd42"
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "652706a3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title(\"Confusion Matrix - Logistic Regression(Churn)\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "96d9d4d4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python",
      "language": "python",
      "display_name": "Pyolite (preview)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernel_info": {
      "name": "python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}